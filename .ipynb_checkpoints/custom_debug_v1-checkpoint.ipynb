{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "from utils.config_manager import ConfigManager\n",
    "from preprocessing.data_handling import load_files, Dataset, DataPrepper\n",
    "from utils.decorators import ignore_exception, time_it\n",
    "from utils.scheduling import piecewise_linear_schedule, reduction_schedule\n",
    "from utils.logging import SummaryManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# dynamically allocate GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), 'Physical GPUs,', len(logical_gpus), 'Logical GPUs')\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "@ignore_exception\n",
    "@time_it\n",
    "def validate(model,\n",
    "             val_dataset,\n",
    "             summary_manager):\n",
    "    val_loss = {'loss': 0.}\n",
    "    norm = 0.\n",
    "    for val_mel, val_text, val_stop in val_dataset.all_batches():\n",
    "        model_out = model.val_step(inp=val_text,\n",
    "                                   tar=val_mel,\n",
    "                                   stop_prob=val_stop)\n",
    "        norm += 1\n",
    "        val_loss['loss'] += model_out['loss']\n",
    "    val_loss['loss'] /= norm\n",
    "    summary_manager.display_loss(model_out, tag='Validation', plot_all=True)\n",
    "    summary_manager.display_attention_heads(model_out, tag='ValidationAttentionHeads')\n",
    "    summary_manager.display_mel(mel=model_out['mel_linear'][0], tag=f'Validation/linear_mel_out')\n",
    "    summary_manager.display_mel(mel=model_out['final_output'][0], tag=f'Validation/predicted_mel')\n",
    "    residual = abs(model_out['mel_linear'] - model_out['final_output'])\n",
    "    summary_manager.display_mel(mel=residual[0], tag=f'Validation/conv-linear_residual')\n",
    "    summary_manager.display_mel(mel=val_mel[0], tag=f'Validation/target_mel')\n",
    "    return val_loss['loss']\n",
    "\n",
    "\n",
    "# consuming CLI, creating paths and directories, load data\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--config', dest='config', type=str)\n",
    "# parser.add_argument('--reset_dir', dest='clear_dir', action='store_true',\n",
    "#                     help=\"deletes everything under this config's folder.\")\n",
    "# parser.add_argument('--reset_logs', dest='clear_logs', action='store_true',\n",
    "#                     help=\"deletes logs under this config's folder.\")\n",
    "# parser.add_argument('--reset_weights', dest='clear_weights', action='store_true',\n",
    "#                     help=\"deletes weights under this config's folder.\")\n",
    "# parser.add_argument('--session_name', dest='session_name', default=None)\n",
    "# args = parser.parse_args()\n",
    "config_manager = ConfigManager(config_path='config/melgan', model_kind='autoregressive', session_name = None)\n",
    "config = config_manager.config\n",
    "# config_manager.create_remove_dirs(clear_dir=args.clear_dir,\n",
    "#                                   clear_logs=args.clear_logs,\n",
    "#                                   clear_weights=args.clear_weights)\n",
    "config_manager.dump_config()\n",
    "config_manager.print_config()\n",
    "\n",
    "train_samples, _ = load_files(metafile=str(config_manager.train_datadir / 'train_metafile.txt'),\n",
    "                              meldir=str(config_manager.train_datadir / 'mels'),\n",
    "                              num_samples=config['n_samples'])  # (phonemes, mel)\n",
    "val_samples, _ = load_files(metafile=str(config_manager.train_datadir / 'test_metafile.txt'),\n",
    "                            meldir=str(config_manager.train_datadir / 'mels'),\n",
    "                            num_samples=config['n_samples'])  # (phonemes, text, mel)\n",
    "\n",
    "# get model, prepare data for model, create datasets\n",
    "pretrained = True\n",
    "if pretrained:\n",
    "    model = config_manager.load_model(str(config_manager.weights_dir /'ckpt-90'))\n",
    "else:\n",
    "    model = config_manager.get_model()\n",
    "\n",
    "config_manager.compile_model(model)\n",
    "data_prep = DataPrepper(config=config,\n",
    "                        tokenizer=model.text_pipeline.tokenizer)\n",
    "\n",
    "test_list = [data_prep(s) for s in val_samples]\n",
    "train_dataset = Dataset(samples=train_samples,\n",
    "                        preprocessor=data_prep,\n",
    "                        batch_size=config['batch_size'],\n",
    "                        mel_channels=config['mel_channels'],\n",
    "                        shuffle=True)\n",
    "val_dataset = Dataset(samples=val_samples,\n",
    "                      preprocessor=data_prep,\n",
    "                      batch_size=10,\n",
    "                      mel_channels=config['mel_channels'],\n",
    "                      shuffle=False)\n",
    "\n",
    "# create logger and checkpointer and restore latest model\n",
    "\n",
    "summary_manager = SummaryManager(model=model, log_dir=config_manager.log_dir, config=config)\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1),\n",
    "                                 optimizer=model.optimizer,\n",
    "                                 net=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, str(config_manager.weights_dir),\n",
    "                                     max_to_keep=config['keep_n_weights'],\n",
    "                                     keep_checkpoint_every_n_hours=config['keep_checkpoint_every_n_hours'])\n",
    "checkpoint.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(f'\\nresuming training from step {model.step} ({manager.latest_checkpoint})')\n",
    "else:\n",
    "    print(f'\\nstarting training from scratch')\n",
    "    \n",
    "if config['debug'] is True:\n",
    "    print('\\nWARNING: DEBUG is set to True. Training in eager mode.')\n",
    "# main event\n",
    "print('\\nTRAINING')\n",
    "losses = []\n",
    "_ = train_dataset.next_batch()\n",
    "t = trange(model.step, config['max_steps'], leave=True)\n",
    "for _ in t:\n",
    "    t.set_description(f'step {model.step}')\n",
    "    mel, phonemes, stop = train_dataset.next_batch()\n",
    "    decoder_prenet_dropout = piecewise_linear_schedule(model.step, config['decoder_prenet_dropout_schedule'])\n",
    "    learning_rate = piecewise_linear_schedule(model.step, config['learning_rate_schedule'])\n",
    "    reduction_factor = reduction_schedule(model.step, config['reduction_factor_schedule'])\n",
    "    drop_n_heads = tf.cast(reduction_schedule(model.step, config['head_drop_schedule']), tf.int32)\n",
    "    t.display(f'reduction factor {reduction_factor}', pos=10)\n",
    "    model.set_constants(decoder_prenet_dropout=decoder_prenet_dropout,\n",
    "                        learning_rate=learning_rate,\n",
    "                        reduction_factor=reduction_factor,\n",
    "                        drop_n_heads=drop_n_heads)\n",
    "    output = model.train_step(inp=phonemes,\n",
    "                              tar=mel,\n",
    "                              stop_prob=stop)\n",
    "    losses.append(float(output['loss']))\n",
    "    \n",
    "    \n",
    "    t.display(f'step loss: {losses[-1]}', pos=1)\n",
    "    for pos, n_steps in enumerate(config['n_steps_avg_losses']):\n",
    "        if len(losses) > n_steps:\n",
    "            t.display(f'{n_steps}-steps average loss: {sum(losses[-n_steps:]) / n_steps}', pos=pos + 2)\n",
    "    \n",
    "    summary_manager.display_loss(output, tag='Train')\n",
    "    summary_manager.display_scalar(tag='Meta/decoder_prenet_dropout', scalar_value=model.decoder_prenet.rate)\n",
    "    summary_manager.display_scalar(tag='Meta/learning_rate', scalar_value=model.optimizer.lr)\n",
    "    summary_manager.display_scalar(tag='Meta/reduction_factor', scalar_value=model.r)\n",
    "    summary_manager.display_scalar(tag='Meta/drop_n_heads', scalar_value=model.drop_n_heads)\n",
    "    if model.step % config['train_images_plotting_frequency'] == 0:\n",
    "        summary_manager.display_attention_heads(output, tag='TrainAttentionHeads')\n",
    "        summary_manager.display_mel(mel=output['mel_linear'][0], tag=f'Train/linear_mel_out')\n",
    "        summary_manager.display_mel(mel=output['final_output'][0], tag=f'Train/predicted_mel')\n",
    "        residual = abs(output['mel_linear'] - output['final_output'])\n",
    "        summary_manager.display_mel(mel=residual[0], tag=f'Train/conv-linear_residual')\n",
    "        summary_manager.display_mel(mel=mel[0], tag=f'Train/target_mel')\n",
    "    \n",
    "    if model.step % config['weights_save_frequency'] == 0:\n",
    "        save_path = manager.save()\n",
    "        t.display(f'checkpoint at step {model.step}: {save_path}', pos=len(config['n_steps_avg_losses']) + 2)\n",
    "    \n",
    "    if model.step % config['validation_frequency'] == 0:\n",
    "        val_loss, time_taken = validate(model=model,\n",
    "                                        val_dataset=val_dataset,\n",
    "                                        summary_manager=summary_manager)\n",
    "        t.display(f'validation loss at step {model.step}: {val_loss} (took {time_taken}s)',\n",
    "                  pos=len(config['n_steps_avg_losses']) + 3)\n",
    "    \n",
    "    if model.step % config['prediction_frequency'] == 0 and (model.step >= config['prediction_start_step']):\n",
    "        for j in range(config['n_predictions']):\n",
    "            mel, phonemes, stop = test_list[j]\n",
    "            t.display(f'Predicting {j}', pos=len(config['n_steps_avg_losses']) + 4)\n",
    "            pred = model.predict(phonemes,\n",
    "                                 max_length=mel.shape[0] + 50,\n",
    "                                 encode=False,\n",
    "                                 verbose=False)\n",
    "            pred_mel = pred['mel']\n",
    "            target_mel = mel\n",
    "            summary_manager.display_attention_heads(outputs=pred, tag=f'TestAttentionHeads/sample {j}')\n",
    "            summary_manager.display_mel(mel=pred_mel, tag=f'Test/sample {j}/predicted_mel')\n",
    "            summary_manager.display_mel(mel=target_mel, tag=f'Test/sample {j}/target_mel')\n",
    "            if model.step > config['audio_start_step']:\n",
    "                summary_manager.display_audio(tag=f'Target/sample {j}', mel=target_mel)\n",
    "                summary_manager.display_audio(tag=f'Prediction/sample {j}', mel=pred_mel)\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Text_to_speech'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4c56d032b26c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mText_to_speech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorFlowTTS_master\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_tts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMelGANGeneratorConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTensorFlowTTS_mastertensorflow_tts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMelDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTensorFlowTTS_mastertensorflow_tts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFMelGANGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Text_to_speech'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "sys.path.append(\".\")\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow_tts.configs import MelGANGeneratorConfig\n",
    "from tensorflow_tts.datasets import MelDataset\n",
    "from tensorflow_tts.models import TFMelGANGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: could not retrieve git hash. Command '['git', 'describe', '--always']' returned non-zero exit status 128.\n"
     ]
    }
   ],
   "source": [
    "# Set up the paths\n",
    "from pathlib import Path\n",
    "MelGAN_path = 'melgan/'\n",
    "TTS_path = 'TransformerTTS/'\n",
    "#config_path = Path('ljspeech_melgan_autoregressive_transformer/melgan')\n",
    "config_manager = ConfigManager(config_path='config/melgan', model_kind='autoregressive', session_name = None)\n",
    "import sys\n",
    "sys.path.append(TTS_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using custom trained model\n",
      "WARNING: could not check git hash. Command '['git', 'describe', '--always']' returned non-zero exit status 128.\n",
      "restored weights from logdir/melgan/autoregressive_weights/ckpt-18 at step 180000\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained models\n",
    "from utils.config_manager import ConfigManager\n",
    "from utils.audio import Audio\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "from scipy.io.wavfile import write\n",
    "from phonemizer import phonemize\n",
    "\n",
    "from melgan.model.generator import Generator\n",
    "from melgan.utils.hparams import HParam, load_hparam_str\n",
    "\n",
    "## set the value to true if you want to youse your own model\n",
    "my_model = True\n",
    "\n",
    "#config_loader = ConfigManager(str(config_path), model_kind='autoregressive')\n",
    "audio = Audio(config_manager.config)\n",
    "\n",
    "if my_model:\n",
    "    print('using custom trained model')\n",
    "    conf_path = 'logdir/melgan/'\n",
    "    model = config_manager.load_model(conf_path +'autoregressive_weights/ckpt-18')\n",
    "    \n",
    "#model = config_loader.load_model(str(config_path /'autoregressive_weights/ckpt-90'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesize text\n",
    "sentence = \"hey guys im leaving the group, please, dont add me again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred text mel: 40 stop out: -10.220335960388184"
     ]
    }
   ],
   "source": [
    "out = model.predict(sentence, max_length= 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([410, 80])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['mel'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert spectrogram to wav (with griffin lim)\n",
    "wav = audio.reconstruct_waveform(out['mel'].numpy().T)\n",
    "ipd.display(ipd.Audio(wav, rate=config_manager.config['sampling_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mel = torch.tensor(out['mel'].numpy().T[np.newaxis,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WAV_VALUE = 32768.0\n",
    "def inference(checkpoint_path,config_path,input_mel):\n",
    "    checkpoint = torch.load(checkpoint_path,map_location=torch.device('cpu') )\n",
    "    if config_path is not None:\n",
    "        hp = HParam(config_path)\n",
    "    else:\n",
    "        hp = load_hparam_str(checkpoint['hp_str'])\n",
    "\n",
    "    model = Generator(hp.audio.n_mel_channels)\n",
    "    model.load_state_dict(checkpoint['model_g'])\n",
    "    model.eval(inference=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mel = input_mel\n",
    "        if len(mel.shape) == 2:\n",
    "            mel = mel.unsqueeze(0)\n",
    "        audio = model.inference(mel)\n",
    "        audio = audio.cpu().detach().numpy()\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'vocoder/nvidia_tacotron2_LJ11_epoch6400.pt'\n",
    "default_path = 'melgan/config/default.yaml'\n",
    "audio = inference(checkpoint_path, default_path,mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display audio\n",
    "ipd.display(ipd.Audio(audio, rate=22050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Acer\\Documents\\Sound recordings'\n",
    "txt_path = r'E:\\Jupyter\\Notebooks\\Text_to_speech\\Neural speech synthesis\\TransformerTTS-master\\LJSpeech-1.1\\train_metafile.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_list = []\n",
    "for name in os.listdir(path):\n",
    "    wavs_list.append(name.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wavs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metafile = []\n",
    "with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "    for l in f.readlines():\n",
    "        if l.split('|')[0] in wavs_list:\n",
    "            print(l.split('|')[0])\n",
    "            data_metafile.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = {'loss': 2}\n",
    "norm = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss['loss']/=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_metafile.txt', 'w+', encoding='utf-8') as test_f:\n",
    "    test_f.writelines(data_metafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
